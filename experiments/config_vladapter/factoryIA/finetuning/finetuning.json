{
    "adam_eps": 1e-06,
    "batch_size": 4,
    "clip_grad_norm": -1.0,
    "warmup_ratio": 0.05,
    "weight_decay": 0.00,
    "epochs": 100,
    "fp16": true,
    "gradient_accumulation_steps": 1,
    "lr": 0.0001,
    "num_workers": 2,
    "optim": "adamw",
    "output": "snap/adapter_training/",
    "seed": 0,
    "test": false,
    "test_only": false,
    "valid_batch_size": 4,
    "train":true,
    "log_tensorboard_path":"tensorboard/clip_multitask_finetuning/",
    "tokenizer_path": "experiments/config_vladapter/factoryIA/prompt/TokenizerConfig.json",
    "dataset_path": "/home/users/pgrimal/data/datasets/miniviquae",
    "kb_path": "/home/users/pgrimal/data/datasets/kb",
    "passages_path": "/home/users/pgrimal/data/datasets/passages",
    "key_relevant": "provenance_indices",
    "key_text_question": "input",
    "key_text_passage": "passage",
    "key_vision_features": "clip_features",
    "key_vision_boxes":null,
    "key_irrelevant": "BM25_irrelevant_indices"
}